{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Signal Classification with BDTs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Consider a search for a Vector-like quark (VLQ) particle of unkown mass. \n",
    "\n",
    "The search is performed in the $B\\to\\;b\\;H(\\to\\;\\gamma\\gamma)$ channel.\n",
    "\n",
    "Simulation samples have been generated for different VLQ masses: 800, 1000, 1200, 1500, 1800, 2000, 2200 GeV\n",
    "\n",
    "This notebook explores the performance of a BDT (trained using a single VLQ mass) in separating signal candidates from $tHq$ candidates (dominant bkg)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Load the signal trees for different VLQ mass points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "\n",
    "masses = [800, 1000, 1200, 1500, 1800, 2000, 2200]\n",
    "datadir = \"../data\"\n",
    "treename = \"BbH_tree\"\n",
    "trees = {\n",
    "    mass: uproot.open(f\"{datadir}/BDT_tree_M{mass}_14TeV.root\")[treename]\n",
    "    for mass in masses\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Load the background tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees[0] = uproot.open(f\"{datadir}/BKG_tree_tHq_14TeV.root\")[treename]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Import variable definitions and groups of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from b2bH_vlq import get_variable_group_names, get_variables_by_group\n",
    "get_variable_group_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = {}\n",
    "for gr in get_variable_group_names():\n",
    "    all_vars.update(get_variables_by_group(gr))\n",
    "all_vars.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Vizualize distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Plot reconstructed $m(b\\gamma\\gamma)$ distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepkit.histograms import hist1d_from_var\n",
    "\n",
    "def fill_histograms(group:str):\n",
    "    vars = get_variables_by_group(group)\n",
    "    hists ={}\n",
    "    for mass in masses + [0]:\n",
    "        tree = trees[mass]\n",
    "        hists[mass] = {\n",
    "            k: hist1d_from_var(\n",
    "                var,\n",
    "                tree,\n",
    "            )\n",
    "            for k, var in vars.items()\n",
    "        }\n",
    "    return hists\n",
    "\n",
    "hist_masses = fill_histograms(\"masses\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from hepkit.histograms import plot_hist1d_comparison\n",
    "from hepkit.plotting import set_cms_style, get_color_palette\n",
    "set_cms_style(grid=True)\n",
    "\n",
    "fi, ax = plt.subplots(figsize=(7,6))\n",
    "colors = get_color_palette(n_colors=len(masses) + 1)\n",
    "plot_hist1d_comparison(\n",
    "    [ hist_masses[mass]['VLQ_mass'] for mass in masses + [0] ],\n",
    "    [ f\"Signal M={mass} GeV\" for mass in masses ] + [\"Background\"],\n",
    "    ax=ax,\n",
    "    colors=colors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_photon1 = fill_histograms(\"photon1\")\n",
    "hist_photon2 = fill_histograms(\"photon2\")\n",
    "hist_diphoton = fill_histograms(\"diphoton\")\n",
    "hist_bjet1 = fill_histograms(\"bjet1\")\n",
    "hists_event = fill_histograms(\"event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepkit.histograms import multi_hist1d_comparison\n",
    "\n",
    "colors = get_color_palette(n_colors=len(masses) + 1)\n",
    "legends = [ f\"Signal M={mass} GeV\" for mass in masses ] + [\"Background\"]\n",
    "histtypes = [\"step\"] * len(masses) + [\"fill\"]\n",
    "for hists in [hist_photon1, hist_photon2, hist_diphoton, hist_bjet1, hists_event]:\n",
    "    multi_hist1d_comparison(\n",
    "        [ hists[mass] for mass in masses + [0] ],\n",
    "        legends,\n",
    "        histtypes,\n",
    "        colors,\n",
    "        figsize_per_plot=(3.0,2.5),\n",
    "        max_cols=4,\n",
    "        subplot_titles=False\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Train a Catboost classifier using the 800 GeV signal sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigdf = trees[800].arrays(library=\"pd\")\n",
    "bkgdf = trees[0].arrays(library=\"pd\")\n",
    "sigdf.shape, bkgdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sig = sigdf[\"evt_weight\"]\n",
    "w_bkg = bkgdf[\"evt_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Input features\n",
    "\n",
    "Select as input features kinematic variables $p_{T}$ and $\\eta$ from  the VLQ candidate and its decay products.\n",
    "\n",
    "Also include $H_{T}$ and deltaR between b-jet and Higgs candidates.\n",
    "\n",
    "Include multiplicity (n-b-jets, n-fwd-jets) as categoraical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "cands = [\"photon1\", \"photon2\", \"diphoton\", \"bjet\", \"VLQ\"]\n",
    "obs = [\"pt\", \"eta\", \"phi\"]\n",
    "\n",
    "mva_vars = { }\n",
    "for cand, obs in product(cands, obs):\n",
    "    key = f\"{cand}_{obs}\"\n",
    "    mva_vars[key] = all_vars[key]\n",
    "mva_vars[\"HT\"] = all_vars[\"HT\"]\n",
    "mva_vars[\"deltaR_bjet_Higgs\"] = all_vars[\"deltaR_bjet_Higgs\"]\n",
    "mva_vars[\"bjet_multiplicity\"] = all_vars[\"bjet_multiplicity\"]\n",
    "mva_vars[\"jet_multiplicity\"] = all_vars[\"jet_multiplicity\"]\n",
    "mva_vars[\"forwardjet_multiplicity\"] = all_vars[\"forwardjet_multiplicity\"]\n",
    "mva_vars.keys();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Compare signal and background distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mva_names = list(mva_vars.keys())\n",
    "hist_mva_sig = {}\n",
    "hist_mva_bkg = {}\n",
    "for name in mva_names:\n",
    "    var = mva_vars[name]\n",
    "    hist_mva_sig[name] = hist1d_from_var(var, sigdf)\n",
    "    hist_mva_bkg[name] = hist1d_from_var(var, bkgdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepkit.classification.visualization import plot_signal_background_comparison\n",
    "fig = plot_signal_background_comparison(\n",
    "    hist_mva_sig, hist_mva_bkg, subplot_titles=False, max_cols=4, figsize_per_plot=(2.5,2.),\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Preprocess the data and prepare training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from hepkit.classification.preprocessing import prepare_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = prepare_training_data(\n",
    "    sigdf,\n",
    "    bkgdf,\n",
    "    mva_vars.values(),\n",
    "    mva_vars.values(),\n",
    "    #sig_weights=w_sig,\n",
    "    #bkg_weights=w_bkg,\n",
    "    # id_columns=[\"NEvts\"],\n",
    "    cat_vars=[\"bjet_multiplicity\", \"jet_multiplicity\", \"forwardjet_multiplicity\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and validation sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    Xy.drop(\"label\", axis=1), Xy[\"label\"], test_size=0.15, random_state=42, stratify=Xy[\"label\"]\n",
    ")\n",
    "#train_X, val_X, train_y, val_y = train_test_split(\n",
    "#    train_X, train_y, test_size=0.15, random_state=42, stratify=train_y\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ratio of signal and background events in the training set and validation set\n",
    "n_sig_train = sum(train_y==1)\n",
    "n_bkg_train = sum(train_y==0)\n",
    "\n",
    "sigfrac_train = n_sig_train / (n_sig_train + n_bkg_train)\n",
    "sigfrac_train, n_sig_train / n_bkg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_weights = train_X.pop(\"weights\")\n",
    "#val_weights = val_X.pop(\"weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### CatBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool, EFeaturesSelectionAlgorithm, EShapCalcType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"bjet_multiplicity\", \"jet_multiplicity\", \"forwardjet_multiplicity\"]\n",
    "train_pool = Pool(data=train_X, label=train_y, cat_features=cat_features)\n",
    "# val_pool = Pool(data=val_X, label=val_y, cat_features=cat_features)\n",
    "\n",
    "# train_pool = Pool(data=train_X, label=train_y, weight=train_weights)\n",
    "# val_pool = Pool(data=val_X, label=val_y, weight=val_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool.get_embedding_feature_indices()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Train with almost default parameters and small learning rate.\n",
    "\n",
    "Use CatBoost's `cv` function to check the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_bkg = n_sig_train / n_bkg_train\n",
    "\n",
    "cb_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"iterations\": 5000,\n",
    "    \"random_state\": 42,\n",
    "    \"learning_rate\": 0.01,\n",
    "    #\"depth\": 4,\n",
    "    #\"class_weights\": [weight_bkg, 1.0],\n",
    "    #'rsm': 0.5,\n",
    "    #'reg_lambda': 1,\n",
    "    #\"custom_metric\": [\"Accuracy\", \"Precision\"],  # \"Recall\", \"F1\"],\n",
    "    #\"od_wait\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "from hepkit.classification.visualization import plot_roc_auc, plot_train_test_response\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def run_experiment(\n",
    "    train_pool,\n",
    "    test_pool=None,\n",
    "    cv_folds=3,\n",
    "    plot=False,\n",
    "    verbose=False,\n",
    "    random_seed=42,\n",
    "    **params,\n",
    "):\n",
    "    defaults = {\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"iterations\": 3000,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"random_state\": random_seed,\n",
    "        \"od_wait\": 100,\n",
    "    }\n",
    "\n",
    "    model_params = defaults | params\n",
    "    od_wait = model_params.pop(\"od_wait\", 100)\n",
    "    \n",
    "    splitter = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    # run cross-validation\n",
    "    cv_data, cv_models = catboost.cv(\n",
    "        params=model_params,\n",
    "        pool=train_pool,\n",
    "        partition_random_seed=random_seed,\n",
    "        folds = splitter,\n",
    "        verbose=verbose,\n",
    "        plot=plot,\n",
    "        return_models=True,\n",
    "    )\n",
    "\n",
    "    # find best iteration\n",
    "    best_iter_auc = cv_data[\"test-AUC-mean\"].values.argmax()\n",
    "    best_auc = cv_data[\"test-AUC-mean\"].values[best_iter_auc]\n",
    "    best_auc_std = cv_data[\"test-AUC-std\"].values[best_iter_auc]\n",
    "\n",
    "    best_iter_loss = cv_data[\"test-Logloss-mean\"].values.argmin()\n",
    "    best_loss = cv_data[\"test-Logloss-mean\"].values[best_iter_loss]\n",
    "    best_loss_std = cv_data[\"test-Logloss-std\"].values[best_iter_loss]\n",
    "\n",
    "    decimals = max(0, math.ceil(-math.log10(best_auc_std))) if best_auc_std > 0 else 0\n",
    "    print(f\"Best validation AUC: {best_auc:.{decimals}f} +/- {best_auc_std:<.{decimals}f} at iteration {best_iter_auc}\")\n",
    "    \n",
    "    decimals = max(0, math.ceil(-math.log10(best_loss_std))) if best_loss_std > 0 else 0\n",
    "    print(f\"Best validation Logloss: {best_loss:.{decimals}f} +/- {best_loss_std:<.{decimals}f} at iteration {best_iter_loss}\")\n",
    "    \n",
    "    y = train_pool.get_label()\n",
    "    X_dummy = np.zeros(len(y))\n",
    "    splits = splitter.split(X_dummy, y)\n",
    "    train_scores, val_scores = [], []\n",
    "    train_y, val_y = [], []\n",
    "    for i, (train_idx, val_idx) in enumerate(splits):\n",
    "        train_fold = train_pool.slice(train_idx)\n",
    "        val_fold = train_pool.slice(val_idx)\n",
    "        train_proba = cv_models[i].predict(\n",
    "            train_fold, \n",
    "            prediction_type='Probability', \n",
    "            ntree_end=int(best_iter_auc)\n",
    "        )[:, 1]\n",
    "        \n",
    "        val_proba = cv_models[i].predict(\n",
    "            val_fold, \n",
    "            prediction_type='Probability', \n",
    "            ntree_end=int(best_iter_auc)\n",
    "        )[:, 1]\n",
    "        train_scores.append(train_proba)\n",
    "        val_scores.append(val_proba)\n",
    "        train_y.append(train_fold.get_label())\n",
    "        val_y.append(val_fold.get_label())\n",
    "        \n",
    "    fig = plot_roc_auc(\n",
    "        train_y + val_y, \n",
    "        train_scores + val_scores,\n",
    "        labels = [f\"train fold {i}\" for i in range(cv_folds)] + [f\"validation fold {i}\" for i in range(cv_folds)], \n",
    "        fig_size=(6,4),\n",
    "        style=\"rejection\"\n",
    "    )\n",
    "\n",
    "    model_params[\"iterations\"] = best_iter_auc + od_wait\n",
    "    model_params[\"custom_metric\"] = [\"AUC:hints=skip_train~false\"]\n",
    "    model_params[\"od_wait\"] = od_wait\n",
    "    model = CatBoostClassifier(**model_params)\n",
    "\n",
    "    model.fit(train_pool, plot=plot, verbose=verbose)\n",
    "    params = model.get_params()\n",
    "\n",
    "    if mlflow.active_run():\n",
    "        mlflow.log_params(model_params)\n",
    "        mlflow.log_metric(\"cv_auc\", best_auc)\n",
    "        mlflow.log_metric(\"cv_logloss\", best_loss)\n",
    "        mlflow.log_metric(\"train_auc\", model.get_best_score()[\"learn\"][\"AUC\"])\n",
    "        mlflow.log_metric(\"train_logloss\", model.get_best_score()[\"learn\"][\"Logloss\"])\n",
    "        mlflow.log_figure(fig, \"plots/cv_roc_auc.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run_experiment(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify environment variables are loaded\n",
    "print(f\"MLFLOW_TRACKING_URI: {os.getenv('MLFLOW_TRACKING_URI')}\")\n",
    "print(f\"MLFLOW_TRACKING_TOKEN: {'*' * 20 if os.getenv('MLFLOW_TRACKING_TOKEN') else 'Not set'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    experiment_id = mlflow.create_experiment(name=\"catboost-M800-tHq\")\n",
    "except mlflow.exceptions.RestException:\n",
    "    # Experiment already exists, get its ID\n",
    "    experiment = mlflow.get_experiment_by_name(\"catboost-M800-tHq\")\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"initial\"):\n",
    "    model = run_experiment(train_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "PLot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepkit.classification.visualization import plot_learning_curve\n",
    "fig = plot_learning_curve(model, metric=\"Logloss\", fig_size=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepkit.classification.visualization import plot_roc_auc\n",
    "fig = plot_roc_auc(val_y, val_proba[:, 1], fig_size=(6,4), style=\"rejection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_feature_importance(\n",
    "    model: CatBoostClassifier,\n",
    "    feature_names,\n",
    "    max_num_features: int = 20,\n",
    "    ax: plt.Axes | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the feature importance of a CatBoost model and return the axes used.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    feature_importances = model.feature_importances_\n",
    "    indices = np.argsort(feature_importances)[-max_num_features:]\n",
    "    ax.barh(\n",
    "        range(len(indices)), feature_importances[indices], color=\"b\", align=\"center\"\n",
    "    )\n",
    "    ax.set_yticks(range(len(indices)))\n",
    "    ax.set_yticklabels([feature_names[i] for i in indices])\n",
    "    ax.set_xlabel(\"Relative Importance\")\n",
    "    ax.set_title(\"Feature Importances\")\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,6));\n",
    "plot_feature_importance(model, train_X.columns, max_num_features=20, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## xGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(\n",
    "    n_estimators=2500,\n",
    "    #max_depth=2,\n",
    "    learning_rate=0.01,\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(train_X, train_y, eval_set=[(val_X, val_y)], verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_xgb = model_xgb.predict(train_X)\n",
    "train_proba_xgb = model_xgb.predict_proba(train_X) # these are the scores\n",
    "val_predict_xgb = model_xgb.predict(val_X)\n",
    "val_proba_xgb = model_xgb.predict_proba(val_X) # these are the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test_response(\n",
    "    model_xgb,\n",
    "    train_X, train_y, val_X, val_y, log_y=False\n",
    ")\n",
    "plot_train_test_response(\n",
    "    model_xgb,\n",
    "    train_X, train_y, val_X, val_y, log_y=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal_efficiency_vs_background_rejection(train_y, train_proba_xgb[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
